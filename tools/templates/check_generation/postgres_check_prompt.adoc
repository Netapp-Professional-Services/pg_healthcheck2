= PostgreSQL Health Check Generation
:toc: left

You are an expert developer and AI code generator for the pg_healthcheck2 multi-database monitoring framework.

Your task: Generate a complete health check solution as a JSON plan for {{ plugin_name }}.

Your output MUST be a single, valid JSON object with NO additional text, explanations, or markdown formatting.

== Core Architecture Contract

Every health check module MUST implement these two functions:

=== Function 1: Weight Declaration

[source,python]
----
def get_weight():
    """Returns the importance score for this module (1-10)."""
    return 7  # Choose based on severity
----

*Weight Guidelines:*
- *1-3 (Low):* Informational checks, statistics, version info
- *4-6 (Medium):* Performance concerns, configuration recommendations
- *7-8 (High):* Significant operational issues, resource exhaustion
- *9-10 (Critical):* Data corruption risks, service availability threats

=== Function 2: Main Check Execution

[source,python]
----
def run_check_name(connector, settings):
    """
    Performs the health check analysis.
    
    Args:
        connector: Database connector with execute_query() method
        settings: Dictionary of configuration settings
    
    Returns:
        tuple: (asciidoc_report_string, structured_data_dict)
    """
    adoc_content = []  # MUST be a list
    structured_data = {}  # MUST be a dict
    
    # ... check logic ...
    
    return "\n".join(adoc_content), structured_data
----

== Database Interaction Rules (CRITICAL)

*NEVER* use raw cursors or direct database access. *ALWAYS* use the connector's high-level API:

[source,python]
----
# CORRECT: Use connector.execute_query()
formatted, raw = connector.execute_query(query, return_raw=True)

# WRONG: Never do this
cursor = connector.cursor()  # ❌ FORBIDDEN
cursor.execute(query)        # ❌ FORBIDDEN
----

*The connector provides:*
- `connector.execute_query(query, params=None, return_raw=False)` - Core query method
- `connector.version_info` - MAY contain version information (check with hasattr)

*Handle missing attributes gracefully:*
[source,python]
----
# Check if version_info exists before using
if hasattr(connector, 'version_info') and connector.version_info.get('is_v15_or_newer'):
    # Use version-specific query
else:
    # Use generic query
----

== Query Format Rules (CRITICAL)

Queries must be *FUNCTIONS* that return query strings, NOT static constants.

=== Query File Structure

Create query files in: `plugins/{plugin_name}/utils/qrylib/`

*File naming:* Descriptive name matching the check purpose

*Each query file contains FUNCTIONS that return query strings:*

[source,python]
----
def get_query_name(connector):
    """
    Returns the query for [describe purpose].
    
    Args:
        connector: Connector instance (may have version_info)
    
    Returns:
        str: Query in appropriate format for this database technology
    """
    # Adapt query based on connector capabilities if needed
    if hasattr(connector, 'version_info'):
        # Use version-aware logic
        pass
    
    return query_string
----

== Check Module Structure Rules

=== Import Pattern

[source,python]
----
# Import query functions from qrylib
from plugins.{plugin_name}.utils.qrylib.query_file_name import (
    get_query_function_1,
    get_query_function_2
)

def get_weight():
    return 7

def run_check_name(connector, settings):
    adoc_content = []
    structured_data = {}
    
    # Call query function, passing connector
    query = get_query_function_1(connector)
    formatted, raw = connector.execute_query(query, return_raw=True)
    
    # ... process results ...
    
    return "\n".join(adoc_content), structured_data
----

=== Result Handling Pattern

Handle three scenarios: error, no issues, issues found

[source,python]
----
try:
    query = get_details_query(connector)
    formatted, raw = connector.execute_query(query, return_raw=True)
    
    if "[ERROR]" in formatted:
        # Query execution failed
        adoc_content.append(formatted)
        structured_data["section"] = {"status": "error", "data": raw}
    
    elif not raw:
        # No issues detected (healthy state)
        adoc_content.append("[NOTE]\n====\nNo issues detected. System is healthy.\n====\n")
        structured_data["section"] = {"status": "success", "data": []}
    
    else:
        # Issues found - provide warning and data
        adoc_content.append("[WARNING]\n====\n**Action Required:** [Describe the issue and impact]\n====\n")
        adoc_content.append(formatted)
        structured_data["section"] = {"status": "success", "data": raw}

except Exception as e:
    error_msg = f"[ERROR]\n====\nCheck failed: {e}\n====\n"
    adoc_content.append(error_msg)
    structured_data["section"] = {"status": "error", "details": str(e)}
----

=== Settings-Based Thresholds

Use settings for configurable thresholds:

[source,python]
----
def run_memory_check(connector, settings):
    # Get threshold from settings or use default
    threshold_mb = settings.get('memory_threshold_mb', 1000)
    warning_percent = settings.get('memory_warning_percent', 80)
    
    query = get_memory_query(connector)
    formatted, raw = connector.execute_query(query, return_raw=True)
    
    # Use thresholds in logic
    if raw and raw[0].get('used_memory_mb', 0) > threshold_mb:
        adoc_content.append(f"[WARNING]\n====\nMemory usage exceeds {threshold_mb}MB\n====\n")
----

== AsciiDoc Formatting Rules

=== Report Structure

[source,python]
----
adoc_content = [
    "=== Check Title",  # Level 3 header for main check
    ""
]

# Add subsections
adoc_content.append("==== Analysis Results")  # Level 4 for subsections
adoc_content.append("")

# Add content with admonition blocks
adoc_content.append("[WARNING]\n====\n[Describe issue]\n====\n")

# Add data tables (if applicable)
adoc_content.append(formatted)

# Add recommendations
adoc_content.append("\n==== Recommendations")
adoc_content.append("[TIP]\n====\n* Best practice...\n====\n")
----

=== Admonition Blocks

Use semantic admonition types:

- `[CRITICAL]` - Immediate action required, service at risk
- `[WARNING]` - Action required, issues detected
- `[IMPORTANT]` - Key information, configuration guidance
- `[TIP]` - Best practices, recommendations
- `[NOTE]` - Informational, no action needed
- `[ERROR]` - Check execution failed

*Always wrap admonitions with `====` blocks:*

[source,python]
----
adoc_content.append("[WARNING]\n====\n**Action Required:** Description...\n====\n")
----

=== Recommendations Section

For checks that identify issues, include actionable guidance:

[source,python]
----
adoc_content.append("\n==== Recommendations")
adoc_content.append("[TIP]\n====\n"
                    "* **Best Practice:** [Preventive measures]\n"
                    "* **Remediation:** [Steps to fix current issues]\n"
                    "* **Monitoring:** [What to watch going forward]\n"
                    "====\n")
----

== Structured Data Format

[source,python]
----
structured_data = {
    'section_name': {
        'status': 'success',  # or 'error'
        'data': [...],         # List of dicts, single dict, or raw data
        'count': 5             # Optional metadata
    }
}
----

== Unit Test File (Required)

*Path:* `tests/{plugin_name}/checks/test_check_name.py`

[source,python]
----
import unittest
from unittest.mock import Mock
from plugins.{plugin_name}.checks.check_name import run_check_name, get_weight

class TestCheckName(unittest.TestCase):
    def test_run_returns_correct_types(self):
        """Test that run function returns string and dict."""
        mock_connector = Mock()
        mock_connector.execute_query.return_value = ('formatted', {'data': []})
        
        result = run_check_name(mock_connector, {})
        
        self.assertIsInstance(result, tuple)
        self.assertEqual(len(result), 2)
        self.assertIsInstance(result[0], str)
        self.assertIsInstance(result[1], dict)
    
    def test_weight_is_valid(self):
        """Test that weight is between 1 and 10."""
        weight = get_weight()
        self.assertGreaterEqual(weight, 1)
        self.assertLessEqual(weight, 10)

if __name__ == '__main__':
    unittest.main()
----

== Output Format (CRITICAL)

[source,json]
----
{
  "operations": [
    {
      "action": "create_file",
      "path": "plugins/{plugin_name}/checks/check_name.py",
      "content": "..."
    },
    {
      "action": "create_file",
      "path": "plugins/{plugin_name}/utils/qrylib/query_file.py",
      "content": "..."
    },
    {
      "action": "create_file",
      "path": "plugins/{plugin_name}/rules/check_name.json",
      "content": "..."
    },
    {
      "action": "create_file",
      "path": "tests/{plugin_name}/checks/test_check_name.py",
      "content": "..."
    }
  ],
  "integration_step": {
    "target_file_hint": "plugins/{plugin_name}/reports/default.py",
    "instruction": "Add to '[Section Name]' section in REPORT_SECTIONS",
    "code_snippet_to_add": "{'type': 'module', 'module': 'plugins.{plugin_name}.checks.check_name', 'function': 'run_check_name'}"
  }
}
----

*CRITICAL:* Module path MUST be full import path:
✅ `'module': 'plugins.postgres.checks.check_name'`
❌ NOT: `'module': 'check_name'`

== Pre-Submission Validation Checklist

Before outputting JSON, verify:

✅ Query functions return appropriate format for this database
✅ Check module uses connector.execute_query()
✅ Version detection handled gracefully (with hasattr checks)
✅ Admonition blocks used appropriately
✅ Settings-based thresholds where applicable
✅ Integration step has FULL module path
✅ Rule file uses correct schema with metric_keywords


== PostgreSQL-Specific Guidance

=== Query Language

PostgreSQL uses SQL queries that return tabular data.

=== System Catalogs & Views

**Core System Views:**

*pg_stat_user_tables* - Table statistics:
- schemaname, relname, seq_scan, seq_tup_read, idx_scan, idx_tup_fetch
- n_tup_ins, n_tup_upd, n_tup_del, n_tup_hot_upd, n_live_tup, n_dead_tup
- last_vacuum, last_autovacuum, last_analyze, last_autoanalyze

*pg_stat_activity* - Active connections:
- pid, datname, usename, application_name, client_addr, backend_start
- xact_start, query_start, state_change, wait_event_type, wait_event, state, query

*pg_stat_database* - Database-wide statistics:
- datname, numbackends, xact_commit, xact_rollback, blks_read, blks_hit
- tup_returned, tup_fetched, tup_inserted, tup_updated, tup_deleted

*pg_settings* - Configuration parameters:
- name, setting, unit, category, short_desc, context, vartype, source, min_val, max_val

*pg_stat_bgwriter* (PG ≤16) / *pg_stat_checkpointer* (PG 17+):
- **PG 16 and earlier:** checkpoints_timed, checkpoints_req, checkpoint_write_time, checkpoint_sync_time, buffers_checkpoint, buffers_clean, maxwritten_clean, buffers_backend, buffers_backend_fsync, buffers_alloc
- **PG 17+:** num_timed, num_requested, write_time, sync_time, buffers_written (different column names!)

*pg_stat_statements* (extension):
- userid, dbid, query, calls, total_exec_time, min_exec_time, max_exec_time, mean_exec_time
- rows, shared_blks_hit, shared_blks_read, shared_blks_written, temp_blks_read, temp_blks_written

**Version-Specific Tables:**
- PG 17+: pg_stat_checkpointer, pg_stat_io
- PG 16: pg_stat_progress_* views
- PG 13+: pg_stat_wal
- PG 10+: pg_stat_replication with additional columns

=== Version-Aware Queries

**CRITICAL:** Always check PostgreSQL version for schema changes:

[source,python]
----
def get_checkpointer_stats_query(connector):
    """Returns checkpointer statistics query."""
    
    if hasattr(connector, 'version_info'):
        major = connector.version_info.get('major_version', 0)
        
        if major >= 17:
            # PG17+ uses different table and column names
            return """
            SELECT 
                num_timed AS checkpoints_timed,
                num_requested AS checkpoints_req,
                write_time AS checkpoint_write_time,
                sync_time AS checkpoint_sync_time,
                buffers_written AS buffers_checkpoint
            FROM pg_stat_checkpointer;
            """
        else:
            # PG16 and earlier
            return """
            SELECT 
                checkpoints_timed,
                checkpoints_req,
                checkpoint_write_time,
                checkpoint_sync_time,
                buffers_checkpoint,
                buffers_clean,
                maxwritten_clean
            FROM pg_stat_bgwriter;
            """
    
    # Fallback
    return "SELECT * FROM pg_stat_bgwriter;"
----

=== Common Monitoring Patterns

**Table Bloat:**
```sql
SELECT 
    schemaname,
    relname AS tablename,
    n_dead_tup,
    n_live_tup,
    ROUND(100.0 * n_dead_tup / NULLIF(n_live_tup + n_dead_tup, 0), 2) AS dead_tuple_percent
FROM pg_stat_user_tables
WHERE n_dead_tup > 1000
ORDER BY n_dead_tup DESC;
```

**Connection Usage:**
```sql
SELECT 
    COUNT(*) AS total_connections,
    (SELECT setting::int FROM pg_settings WHERE name = 'max_connections') AS max_connections
FROM pg_stat_activity
WHERE pid IS NOT NULL;
```

**Index Usage:**
```sql
SELECT 
    schemaname,
    relname AS tablename,
    indexrelname AS indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
WHERE idx_scan = 0
  AND pg_relation_size(indexrelid) > 1048576  -- > 1MB
ORDER BY pg_relation_size(indexrelid) DESC;
```

**Slow Queries (requires pg_stat_statements):**
```sql
SELECT 
    query,
    calls,
    ROUND(total_exec_time::numeric, 2) AS total_time_ms,
    ROUND(mean_exec_time::numeric, 2) AS avg_time_ms,
    ROUND((100 * total_exec_time / SUM(total_exec_time) OVER ())::numeric, 2) AS percent_total
FROM pg_stat_statements
WHERE query NOT LIKE '%pg_stat_statements%'
ORDER BY total_exec_time DESC
LIMIT 20;
```

=== Column Name Pitfalls

**Common Mistakes:**
- ❌ `tablename` → ✅ `relname` (in pg_stat_user_tables)
- ❌ `indexname` → ✅ `indexrelname` (in pg_stat_user_indexes)
- ❌ `session_id` → ✅ `pid` (in pg_stat_activity)
- ❌ Using PG17 column names on PG16 or vice versa

=== Extensions to Check

Common extensions that provide monitoring data:
- `pg_stat_statements` - Query performance statistics
- `pg_buffercache` - Buffer cache inspection
- `pgstattuple` - Tuple-level statistics and bloat

Check availability before using:
```sql
SELECT COUNT(*) > 0 AS has_pg_stat_statements
FROM pg_extension
WHERE extname = 'pg_stat_statements';
```

=== Best Practices

1. **Always use relname, not tablename** in pg_stat_* views
2. **Check version** before using version-specific views
3. **Handle division by zero** with NULLIF() or GREATEST()
4. **Use pg_size_pretty()** for human-readable sizes
5. **Filter system schemas** with `schemaname NOT IN ('pg_catalog', 'information_schema')`
6. **Limit large result sets** to prevent overwhelming output

== Your Task

Generate a PostgreSQL health check for:

*Plugin Name:* {{ plugin_name }}
*Request:* {{ natural_language_request }}

Output ONLY the JSON plan. No explanations, no markdown, no additional text.
