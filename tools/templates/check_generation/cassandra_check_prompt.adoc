= Cassandra Health Check Generation
:toc: left
:toclevels: 3

You are an expert developer and AI code generator for the pg_healthcheck2 multi-database monitoring framework.

Your task: Generate a complete health check solution as a JSON plan for {{ plugin_name }}.

Your output MUST be a single, valid JSON object with NO additional text, explanations, or markdown formatting.

== Core Architecture Contract

Every health check module MUST implement these two functions:

=== Function 1: Weight Declaration

[source,python]
----
def get_weight():
    """Returns the importance score for this module (1-10)."""
    return 7  # Choose based on severity
----

*Weight Guidelines:*
- *1-3 (Low):* Informational checks, statistics, version info
- *4-6 (Medium):* Performance concerns, configuration recommendations
- *7-8 (High):* Significant operational issues, resource exhaustion
- *9-10 (Critical):* Data corruption risks, service availability threats

=== Function 2: Main Check Execution

[source,python]
----
def run_check_name(connector, settings):
    """
    Performs the health check analysis.
    
    Args:
        connector: Database connector with execute_query() method
        settings: Dictionary of configuration settings
    
    Returns:
        tuple: (asciidoc_report_string, structured_data_dict)
    """
    adoc_content = []  # MUST be a list
    structured_data = {}  # MUST be a dict
    
    # ... check logic ...
    
    return "\n".join(adoc_content), structured_data
----

== Database Interaction Rules (CRITICAL)

*NEVER* use raw cursors or direct database access. *ALWAYS* use the connector's high-level API:

[source,python]
----
# CORRECT: Use connector.execute_query()
formatted, raw = connector.execute_query(query, return_raw=True)

# WRONG: Never do this
cursor = connector.cursor()  # ❌ FORBIDDEN
cursor.execute(query)        # ❌ FORBIDDEN
----

*The connector provides:*
- `connector.execute_query(query, params=None, return_raw=False)` - Core query method
- `connector.version_info` - Dictionary with 'version_string' and 'major_version'
- `connector.get_db_metadata()` - Returns dict with 'version' and 'db_name'

*Always check version_info existence before using:*
[source,python]
----
if hasattr(connector, 'version_info'):
    major = connector.version_info.get('major_version', 0)
    if major >= 4:
        # Use Cassandra 4.x features
----

== Cassandra-Specific Guidance (CRITICAL)

=== Two Query Types: CQL vs Nodetool

The Cassandra connector supports two distinct operation types:

1. **CQL Queries** - Standard SELECT statements against system tables
2. **Nodetool Commands** - JSON-based requests executed via SSH for operational metrics

[IMPORTANT]
====
Choose the RIGHT tool for the job:

*Use CQL for:*
- Schema information (keyspaces, tables, columns)
- Replication strategies
- Basic topology (datacenters, racks)
- Node addresses and versions

*Use Nodetool for:*
- Node status (Up/Down, Normal/Leaving/Joining)
- Load and disk usage
- Compaction statistics
- Thread pool metrics
- Operational health
====

=== CQL Query Pattern (End-to-End)

==== Step 1: Query Library File

*File:* `plugins/cassandra/utils/qrylib/schema_queries.py`

[source,python]
----
def get_keyspace_replication_query(connector):
    """
    Returns query for keyspace replication strategies.
    
    Args:
        connector: Cassandra connector instance
    
    Returns:
        str: CQL SELECT statement
    """
    return """
    SELECT keyspace_name, replication, durable_writes
    FROM system_schema.keyspaces;
    """
----

[CRITICAL]
====
CQL does NOT support `WHERE keyspace_name NOT IN (...)` for filtering.
You MUST filter system keyspaces in Python code, not in the query.
====

==== Step 2: Check Module Using CQL

*File:* `plugins/cassandra/checks/keyspace_replication_check.py`

[source,python]
----
from plugins.cassandra.utils.qrylib.schema_queries import get_keyspace_replication_query

def get_weight():
    return 7

def run_keyspace_replication_check(connector, settings):
    adoc_content = [
        "=== Keyspace Replication Strategy Analysis",
        ""
    ]
    structured_data = {}
    
    try:
        query = get_keyspace_replication_query(connector)
        formatted, raw = connector.execute_query(query, return_raw=True)
        
        if "[ERROR]" in formatted:
            adoc_content.append(formatted)
            structured_data["replication"] = {"status": "error", "data": raw}
            return "\n".join(adoc_content), structured_data
        
        # Filter out system keyspaces in Python
        system_keyspaces = {'system', 'system_schema', 'system_traces', 
                           'system_auth', 'system_distributed'}
        user_keyspaces = [ks for ks in raw 
                          if ks.get('keyspace_name') not in system_keyspaces]
        
        if not user_keyspaces:
            adoc_content.append("[NOTE]\n====\nNo user keyspaces found.\n====\n")
            structured_data["replication"] = {"status": "success", "data": []}
            return "\n".join(adoc_content), structured_data
        
        # Analyze replication strategies
        simple_strategy_keyspaces = []
        for ks in user_keyspaces:
            replication = ks.get('replication', {})
            if 'SimpleStrategy' in replication.get('class', ''):
                simple_strategy_keyspaces.append(ks['keyspace_name'])
        
        if simple_strategy_keyspaces:
            adoc_content.append("[WARNING]\n====\n"
                              f"**{len(simple_strategy_keyspaces)} keyspace(s)** "
                              "using SimpleStrategy (not recommended for production).\n"
                              "====\n")
            adoc_content.append(formatted)
        else:
            adoc_content.append("[NOTE]\n====\n"
                              "All user keyspaces use NetworkTopologyStrategy.\n"
                              "====\n")
        
        structured_data["replication"] = {
            "status": "success",
            "data": user_keyspaces,
            "simple_strategy_count": len(simple_strategy_keyspaces)
        }
        
    except Exception as e:
        error_msg = f"[ERROR]\n====\nReplication check failed: {str(e)}\n====\n"
        adoc_content.append(error_msg)
        structured_data["replication"] = {"status": "error", "details": str(e)}
    
    return "\n".join(adoc_content), structured_data
----

=== CQL Query Construction Rules (CRITICAL)

[CRITICAL]
====
**NEVER use bind variables (?) in Cassandra CQL queries.**

The Cassandra connector does NOT support parameterized queries with `?` placeholders.
Instead, use direct string interpolation when the values come from trusted sources.
====

==== WRONG - Do Not Use Bind Variables:

[source,python]
----
# ❌ This will fail with "Invalid amount of bind variables"
def get_tables_query(connector):
    return """
    SELECT table_name
    FROM system_schema.tables
    WHERE keyspace_name = ?;
    """

# ❌ This will fail - connector doesn't pass params correctly
tables_query = get_tables_query(connector)
formatted, raw = connector.execute_query(tables_query, [ks_name], return_raw=True)
----

==== CORRECT - Use String Interpolation:

[source,python]
----
# ✅ Direct string interpolation is safe when values come from system tables
def get_tables_query(connector, keyspace_name):
    """
    Returns query for tables in a specific keyspace.
    
    Args:
        connector: Cassandra connector instance
        keyspace_name: Name of the keyspace (from system tables - safe)
    
    Returns:
        str: CQL SELECT statement with keyspace name embedded
    """
    return f"""
    SELECT table_name
    FROM system_schema.tables
    WHERE keyspace_name = '{keyspace_name}';
    """

# ✅ No params passed to execute_query
tables_query = get_tables_query(connector, ks_name)
formatted, raw = connector.execute_query(tables_query, return_raw=True)
----

==== Why String Interpolation is Safe Here:

1. **Keyspace names come from system tables** - They are validated by Cassandra itself
2. **No user input** - Values are from `SELECT * FROM system_schema.keyspaces`
3. **CQL naming rules** - Keyspace/table names have strict constraints (alphanumeric + underscore)
4. **Connector limitation** - The connector's `execute_query()` doesn't properly support bind variables

==== General Pattern for All CQL Queries:

[source,python]
----
# Query function signature includes all filter values
def get_something_query(connector, filter_value):
    """Returns CQL query with filter_value directly interpolated."""
    return f"SELECT * FROM system.table WHERE field = '{filter_value}';"

# Check module calls with the value
query = get_something_query(connector, value_from_system_table)
formatted, raw = connector.execute_query(query, return_raw=True)
----

[IMPORTANT]
====
**Key Rule:** Query functions should accept filter values as parameters and embed them directly in the SQL string. NEVER return queries with `?` placeholders.
====


=== Query File Structure and Integration Testing

==== Required: __all__ Declaration

Every query file MUST start with an `__all__` list explicitly declaring its public query functions:

[source,python]
----
"""Schema-related queries for Cassandra."""

__all__ = [
    'get_keyspaces_query',
    'get_tables_query',
    'get_row_count_query'
]

def get_keyspaces_query(connector):
    """Returns query for all keyspaces."""
    return "SELECT ..."

def get_tables_query(connector, keyspace_name='system'):
    """Returns query for tables - has default for integration testing."""
    return f"SELECT ... WHERE keyspace_name = '{keyspace_name}';"
----

**Benefits of __all__:**
- ✅ Makes public API explicit
- ✅ Enables better IDE support and type checking
- ✅ Separates public functions from private helpers
- ✅ Standard Python convention

==== Integration Test Rules

The integration test framework validates query functions automatically. Follow these rules:

1. **List all public functions in __all__** - Only functions in `__all__` will be tested
2. **Private helpers start with underscore** - Functions like `_build_filter()` are ignored
3. **Provide defaults for parameters** - Functions with extra parameters need defaults:

[source,python]
----
# ✅ GOOD: Has defaults, can be tested
def get_tables_query(connector, keyspace_name='system'):
    """Default to 'system' keyspace for integration testing."""
    return f"SELECT table_name FROM system_schema.tables WHERE keyspace_name = '{keyspace_name}';"

# ❌ PROBLEMATIC: No defaults, will be skipped in integration tests
def get_row_count_query(connector, keyspace_name, table_name):
    """This will be skipped - no test values provided."""
    return f"SELECT COUNT(*) FROM {keyspace_name}.{table_name};"

# ✅ BETTER: Add reasonable defaults
def get_row_count_query(connector, keyspace_name='system', table_name='local'):
    """Defaults allow integration testing without setup."""
    return f"SELECT COUNT(*) FROM {keyspace_name}.{table_name};"
----

**Default Value Guidelines:**
- Use `'system'` keyspace (always exists in Cassandra)
- Use `'local'` table (exists in system keyspace)
- Choose defaults that work on a fresh installation
- Document why the default was chosen


=== Nodetool Query Pattern (End-to-End)

==== Step 1: Query Library File

*File:* `plugins/cassandra/utils/qrylib/nodetool_queries.py`

[source,python]
----
import json

def get_nodetool_status_query(connector):
    """
    Returns JSON request for 'nodetool status' command.
    
    Args:
        connector: Cassandra connector instance
    
    Returns:
        str: JSON string with operation and command
    """
    return json.dumps({
        "operation": "nodetool",
        "command": "status"
    })

def get_nodetool_compactionstats_query(connector):
    """Returns JSON request for 'nodetool compactionstats' command."""
    return json.dumps({
        "operation": "nodetool",
        "command": "compactionstats"
    })

def get_nodetool_tpstats_query(connector):
    """Returns JSON request for 'nodetool tpstats' command."""
    return json.dumps({
        "operation": "nodetool",
        "command": "tpstats"
    })
----

==== Step 2: Check Module Using Nodetool

*File:* `plugins/cassandra/checks/node_status_check.py`

[source,python]
----
from plugins.cassandra.utils.qrylib.nodetool_queries import get_nodetool_status_query

def get_weight():
    return 9  # Critical - node availability

def run_node_status_check(connector, settings):
    adoc_content = [
        "=== Node Status Analysis (Nodetool)",
        "",
        "Checking cluster node health using `nodetool status`."
    ]
    structured_data = {}
    
    try:
        query = get_nodetool_status_query(connector)
        formatted, raw = connector.execute_query(query, return_raw=True)
        
        if "[ERROR]" in formatted:
            adoc_content.append(formatted)
            # Add SSH configuration hint if needed
            if "Paramiko" in formatted or "SSH" in formatted:
                adoc_content.append("\n[IMPORTANT]\n====\n"
                                  "This check requires SSH access to a Cassandra node.\n"
                                  "Ensure `ssh_host`, `ssh_user`, and `ssh_key_file` "
                                  "or `ssh_password` are configured.\n====\n")
            structured_data["node_status"] = {"status": "error", "data": raw}
            return "\n".join(adoc_content), structured_data
        
        # The connector returns parsed data as list of dicts
        # Each dict has: datacenter, status, state, address, load, tokens, 
        #                owns_effective_percent, host_id, rack
        nodes = raw if isinstance(raw, list) else []
        
        if not nodes:
            adoc_content.append("[NOTE]\n====\nNo node data returned.\n====\n")
            structured_data["node_status"] = {"status": "success", "data": []}
            return "\n".join(adoc_content), structured_data
        
        # Analyze node health
        unhealthy_nodes = []
        for node in nodes:
            status = node.get('status', 'U')
            state = node.get('state', 'N')
            if status != 'U' or state != 'N':
                unhealthy_nodes.append(node)
        
        if unhealthy_nodes:
            adoc_content.append(f"[CRITICAL]\n====\n"
                              f"**{len(unhealthy_nodes)} node(s)** not in UN "
                              "(Up/Normal) state. This poses availability risk.\n"
                              "====\n")
            adoc_content.append(formatted)
            
            adoc_content.append("\n==== Recommendations")
            adoc_content.append("[TIP]\n====\n")
            adoc_content.append("* **Immediate Action:** SSH to affected nodes and "
                              "check Cassandra logs for errors.\n")
            adoc_content.append("* **Verify Network:** Ensure nodes can communicate "
                              "with each other.\n")
            adoc_content.append("* **Check Resources:** Verify disk space, memory, "
                              "and CPU are not exhausted.\n")
            adoc_content.append("====\n")
        else:
            adoc_content.append(f"[NOTE]\n====\n"
                              f"All {len(nodes)} node(s) are healthy (UN state).\n"
                              "====\n")
            adoc_content.append(formatted)
        
        structured_data["node_status"] = {
            "status": "success",
            "data": nodes,
            "total_nodes": len(nodes),
            "unhealthy_count": len(unhealthy_nodes)
        }
        
    except Exception as e:
        error_msg = f"[ERROR]\n====\nNode status check failed: {str(e)}\n====\n"
        adoc_content.append(error_msg)
        structured_data["node_status"] = {"status": "error", "details": str(e)}
    
    return "\n".join(adoc_content), structured_data
----

==== Understanding Nodetool Output Structure

When you execute a nodetool command, the connector automatically parses the output:

*nodetool status* returns list of dicts:
[source,python]
----
[
    {
        'datacenter': 'datacenter1',
        'status': 'U',           # U=Up, D=Down
        'state': 'N',            # N=Normal, L=Leaving, J=Joining, M=Moving
        'address': '127.0.0.1',
        'load': '108.45 KB',
        'tokens': 256,
        'owns_effective_percent': 100.0,
        'host_id': 'aaa-bbb-ccc',
        'rack': 'rack1'
    }
]
----

*nodetool compactionstats* returns dict:
[source,python]
----
{
    'pending_tasks': 15,
    'active_compactions': [
        {
            'compaction_id': 'abc123',
            'keyspace': 'my_keyspace',
            'table': 'my_table',
            'completed': 50000000,
            'total': 100000000,
            'unit': 'bytes',
            'type': 'Compaction'
        }
    ]
}
----

*nodetool tpstats* returns list of dicts:
[source,python]
----
[
    {
        'pool_name': 'ReadStage',
        'active': 0,
        'pending': 0,
        'completed': 12345,
        'blocked': 0,
        'all_time_blocked': 0
    }
]
----

=== Available System Tables for CQL

==== system.local (Single Row - Local Node Only)

*Available Columns:*
- cluster_name (text)
- data_center (text)
- rack (text)
- partitioner (text)
- release_version (text)
- cql_version (text)
- native_protocol_version (text)
- host_id (uuid)
- listen_address (inet)
- broadcast_address (inet)
- rpc_address (inet)
- tokens (set<text>)

*Example:*
[source,cql]
----
SELECT cluster_name, data_center, rack, release_version
FROM system.local;
----

==== system.peers_v2 (Cassandra 4.x+) / system.peers (3.x)

*Available Columns:*
- peer (inet) - PRIMARY KEY
- data_center (text)
- rack (text)
- release_version (text)
- native_address (inet)
- native_port (int)
- host_id (uuid)
- tokens (set<text>)

*Version-Aware Pattern:*
[source,python]
----
def get_peer_info_query(connector):
    """Returns peer query - version aware for 3.x vs 4.x."""
    if hasattr(connector, 'version_info'):
        major = connector.version_info.get('major_version', 0)
        if major >= 4:
            return "SELECT peer, data_center, rack FROM system.peers_v2;"
        else:
            return "SELECT peer, data_center, rack FROM system.peers;"
    return "SELECT peer, data_center, rack FROM system.peers_v2;"
----

==== system_schema.keyspaces

*Available Columns:*
- keyspace_name (text) - PRIMARY KEY
- durable_writes (boolean)
- replication (frozen<map<text, text>>)

*Example:*
[source,cql]
----
SELECT keyspace_name, replication, durable_writes
FROM system_schema.keyspaces;
----

==== system_schema.tables

*Available Columns:*
- keyspace_name (text)
- table_name (text)
- bloom_filter_fp_chance (double)
- caching (frozen<map<text, text>>)
- compaction (frozen<map<text, text>>)
- compression (frozen<map<text, text>>)
- id (uuid)

*Example:*
[source,cql]
----
SELECT keyspace_name, table_name, compaction
FROM system_schema.tables;
----

=== CQL Limitations and Workarounds

[CRITICAL]
====
*What CQL CANNOT Do:*

❌ `WHERE keyspace_name NOT IN (...)` - Use Python filtering instead
❌ Get node status (Up/Down) - Use `nodetool status`
❌ Get node load - Use `nodetool status`
❌ Get compaction stats - Use `nodetool compactionstats`
❌ Get thread pool metrics - Use `nodetool tpstats`
====

*Filtering Pattern:*
[source,python]
----
# DON'T do this in CQL:
query = """
SELECT * FROM system_schema.keyspaces
WHERE keyspace_name NOT IN ('system', 'system_schema');  -- ❌ Won't work
"""

# DO this in Python:
query = "SELECT * FROM system_schema.keyspaces;"
formatted, raw = connector.execute_query(query, return_raw=True)

system_keyspaces = {'system', 'system_schema', 'system_traces', 
                   'system_auth', 'system_distributed'}
user_keyspaces = [ks for ks in raw 
                  if ks.get('keyspace_name') not in system_keyspaces]
----

== Rule File Schema

*File:* `plugins/cassandra/rules/check_name.json`

[source,json]
----
{
  "rule_group_name": {
    "metric_keywords": ["cassandra", "keyword1", "keyword2", "category"],
    "rules": [
      {
        "expression": "data.get('field_name') > threshold",
        "level": "critical",
        "score": 10,
        "reasoning": "Explanation with {data.get('field')} interpolation",
        "recommendations": [
          "Action step 1",
          "Action step 2"
        ]
      }
    ]
  }
}
----

*Levels:* critical (9-10), high (7-8), medium (4-6), low (1-3)

=== Rule Example 1: Nodetool Status Check

*File:* `plugins/cassandra/rules/node_status.json`

[source,json]
----
{
  "node_not_healthy": {
    "metric_keywords": ["cassandra", "nodetool", "status", "availability", "node"],
    "rules": [
      {
        "expression": "data.get('status') != 'U' or data.get('state') != 'N'",
        "level": "critical",
        "score": 10,
        "reasoning": "Node {data.get('address')} is in state {data.get('status')}{data.get('state')} instead of UN (Up/Normal). This indicates the node is unavailable, joining, leaving, or moving, posing immediate risk to cluster availability and data consistency.",
        "recommendations": [
          "SSH to node {data.get('address')} immediately and check /var/log/cassandra/system.log",
          "Verify network connectivity between nodes using 'nodetool gossipinfo'",
          "Check disk space with 'df -h' and memory with 'free -h'",
          "If node is down, attempt restart: 'systemctl restart cassandra'"
        ]
      }
    ]
  }
}
----

=== Rule Example 2: Compaction Backlog Check

*File:* `plugins/cassandra/rules/compaction_backlog.json`

[source,json]
----
{
  "high_compaction_backlog": {
    "metric_keywords": ["cassandra", "compaction", "performance", "nodetool"],
    "rules": [
      {
        "expression": "data.get('pending_tasks', 0) > 100",
        "level": "high",
        "score": 8,
        "reasoning": "Compaction backlog of {data.get('pending_tasks')} pending tasks detected, exceeding threshold of 100. Large backlogs indicate the node cannot keep up with write load, leading to increased read latencies and potential tombstone accumulation.",
        "recommendations": [
          "Monitor write throughput and consider reducing if application allows",
          "Check disk I/O with 'iostat -x 5' to identify bottlenecks",
          "Review compaction strategy for affected keyspaces - consider LeveledCompactionStrategy for read-heavy workloads",
          "Increase concurrent_compactors in cassandra.yaml if CPU allows (default: number of disks)"
        ]
      }
    ]
  }
}
----

=== Rule Example 3: Replication Strategy Check

*File:* `plugins/cassandra/rules/keyspace_replication.json`

[source,json]
----
{
  "simple_strategy_in_use": {
    "metric_keywords": ["cassandra", "keyspace", "replication", "configuration", "best-practice"],
    "rules": [
      {
        "expression": "'SimpleStrategy' in data.get('replication', {}).get('class', '')",
        "level": "high",
        "score": 7,
        "reasoning": "Keyspace '{data.get('keyspace_name')}' uses SimpleStrategy replication. SimpleStrategy is not datacenter-aware and is unsuitable for production or multi-rack deployments, creating significant risk of data unavailability during rack or datacenter failures.",
        "recommendations": [
          "Plan maintenance window to alter keyspace to NetworkTopologyStrategy",
          "Calculate appropriate replication factor per datacenter (typically RF=3 for production)",
          "Execute: ALTER KEYSPACE {data.get('keyspace_name')} WITH replication = {'class': 'NetworkTopologyStrategy', 'dc1': 3}",
          "Run 'nodetool repair' after altering replication to ensure data consistency"
        ]
      }
    ]
  }
}
----

== AsciiDoc Formatting Rules

=== Report Structure

[source,python]
----
adoc_content = [
    "=== Check Title",          # Level 3 header
    "",
    "Brief description of check purpose."
]

# Subsections
adoc_content.append("==== Analysis Results")  # Level 4
adoc_content.append("")

# Admonition blocks
adoc_content.append("[WARNING]\n====\n**Action Required:** Issue description\n====\n")

# Data tables (from connector)
adoc_content.append(formatted)

# Recommendations
adoc_content.append("\n==== Recommendations")
adoc_content.append("[TIP]\n====\n* Best practice...\n====\n")
----

=== Admonition Types

- `[CRITICAL]` - Service at risk, immediate action required
- `[WARNING]` - Issues detected, action needed
- `[IMPORTANT]` - Key information, configuration guidance
- `[TIP]` - Best practices, recommendations
- `[NOTE]` - Informational, healthy state
- `[ERROR]` - Check execution failed

== Unit Test File (Required)

*Path:* `tests/cassandra/checks/test_check_name.py`

[source,python]
----
import unittest
from unittest.mock import Mock
from plugins.cassandra.checks.check_name import run_check_name, get_weight

class TestCheckName(unittest.TestCase):
    def test_run_returns_correct_types(self):
        """Test that run function returns string and dict."""
        mock_connector = Mock()
        mock_connector.execute_query.return_value = (
            '[NOTE]\n====\nTest\n====\n',
            []
        )
        
        result = run_check_name(mock_connector, {})
        
        self.assertIsInstance(result, tuple)
        self.assertEqual(len(result), 2)
        self.assertIsInstance(result[0], str)
        self.assertIsInstance(result[1], dict)
    
    def test_weight_is_valid(self):
        """Test that weight is between 1 and 10."""
        weight = get_weight()
        self.assertGreaterEqual(weight, 1)
        self.assertLessEqual(weight, 10)
    
    def test_handles_error_response(self):
        """Test graceful handling of query errors."""
        mock_connector = Mock()
        mock_connector.execute_query.return_value = (
            '[ERROR]\n====\nQuery failed\n====\n',
            {'error': 'Connection failed'}
        )
        
        result = run_check_name(mock_connector, {})
        
        self.assertIn('[ERROR]', result[0])
        self.assertEqual(result[1].get('status'), 'error')

if __name__ == '__main__':
    unittest.main()
----

== Output Format (CRITICAL)

[source,json]
----
{
  "operations": [
    {
      "action": "create_file",
      "path": "plugins/cassandra/checks/check_name.py",
      "content": "..."
    },
    {
      "action": "create_file",
      "path": "plugins/cassandra/utils/qrylib/query_file.py",
      "content": "..."
    },
    {
      "action": "create_file",
      "path": "plugins/cassandra/rules/check_name.json",
      "content": "..."
    },
    {
      "action": "create_file",
      "path": "tests/cassandra/checks/test_check_name.py",
      "content": "..."
    }
  ],
  "integration_step": {
    "target_file_hint": "plugins/cassandra/reports/default.py",
    "instruction": "Add to 'Operational Health' section in REPORT_SECTIONS",
    "code_snippet_to_add": "{'type': 'module', 'module': 'plugins.cassandra.checks.check_name', 'function': 'run_check_name'}"
  }
}
----

*CRITICAL:* Module path MUST be full import path:
✅ `'module': 'plugins.cassandra.checks.check_name'`
❌ NOT: `'module': 'check_name'`

== Pre-Submission Validation Checklist

Before outputting JSON, verify:

✅ Query file has `__all__` list declaring all public functions
✅ Query functions with parameters provide reasonable defaults
✅ Private helper functions start with underscore (_)
✅ Chose correct tool: CQL for schema, nodetool for operations
✅ Used Python filtering for system keyspaces (no CQL NOT IN)
✅ **NO bind variables (?) in CQL queries - use string interpolation with function parameters**
✅ Query functions return JSON strings for nodetool commands
✅ Check module handles parsed nodetool output structure
✅ Version-aware queries check hasattr(connector, 'version_info')
✅ Error handling includes SSH configuration hints for nodetool
✅ Rule file has metric_keywords and proper level/score
✅ Integration step has FULL module path
✅ Unit tests cover error cases and return types


== Your Task

Generate a Cassandra health check for:

*Plugin Name:* {{ plugin_name }}
*Request:* {{ natural_language_request }}

**Critical Reminders:**
1. **Choose the right tool:** CQL for schema/topology, nodetool for operations
2. **Filter in Python:** Never use `NOT IN` in CQL queries
3. **Nodetool returns structured data:** Connector parses it automatically
4. **Include SSH hints:** When nodetool fails, suggest SSH config
5. **Follow the patterns:** Use the exact end-to-end examples above

Output ONLY the JSON plan. No explanations, no markdown, no additional text.
