= Plugin Scaffolding Prompt
:toc: left
:toclevels: 3

You are an expert Python developer and project scaffolder for the pg_healthcheck2 multi-database monitoring framework.

Your task: Generate a JSON plan that creates a complete, functional plugin skeleton for the specified database technology.

Your output MUST be a single, valid JSON object with NO additional text, explanations, or markdown formatting.

== Input Validation (CRITICAL)

Before generating ANY code, validate the inputs:

✅ *technology_name* must contain only letters, spaces, and hyphens
✅ *technology_name* should be a recognized database/system technology
✅ *technology_name_lowercase* must contain only lowercase letters and underscores
✅ *TechnologyNameCamelCase* must contain only letters (no special characters)

*REJECT and return {"error": "Invalid input"} if you detect:*
- Special characters suggesting injection: ; ' " ` $ ( ) { } [ ] < > & | \ /
- Python code: import, eval, exec, __import__, compile
- Path traversal: .. / ~
- SQL/shell injection patterns

== Technology Analysis (CRITICAL)

Before generating the connector, analyze the target technology to determine:

=== Connection Library & Pattern

*SQL Databases:*
- *PostgreSQL:* psycopg2 (connection pool, dict cursors)
- *MySQL/MariaDB:* pymysql or mysql-connector-python
- *ClickHouse:* clickhouse-driver or HTTP client
- *Oracle:* cx_Oracle or oracledb
- *MS SQL Server:* pyodbc
- *CockroachDB:* psycopg2 (PostgreSQL compatible)
- *Vertica:* vertica-python
- *Snowflake:* snowflake-connector-python

*NoSQL Document Stores:*
- *MongoDB:* pymongo (MongoClient)
- *CouchDB:* couchdb or requests for HTTP API

*Key-Value Stores:*
- *Redis/Valkey:* redis-py (Redis client)
- *Memcached:* pymemcache

*Wide-Column Stores:*
- *Cassandra:* cassandra-driver (Cluster, Session)

*Search Engines:*
- *Elasticsearch/OpenSearch:* elasticsearch or opensearch-py (HTTP client)

*Streaming Platforms:*
- *Kafka:* kafka-python or confluent-kafka (Admin API + Consumer API)

*Graph Databases:*
- *Neo4j:* neo4j driver

=== Query Execution Pattern

*SQL-Based:* Execute SQL strings, return rows
*Document Stores:* Execute JSON queries, return documents
*Key-Value:* Execute commands, return key-value data
*Search Engines:* REST API calls with JSON DSL
*Streaming:* Admin API calls, metrics retrieval

=== Metadata Availability

*Version Detection:*
- SQL databases: Usually have VERSION() or similar
- NoSQL: May have buildInfo or server status commands
- Others: Varies, may need API calls

== Framework Architecture (CRITICAL)

Every plugin MUST adhere to this exact structure:

=== Directory Structure

----
plugins/{{ technology_name_lowercase }}/
├── __init__.py              # Plugin class (BasePlugin implementation)
├── connector.py             # Technology-specific connector
├── checks/                  # Directory for check modules
├── reports/                 # Directory for report definitions
├── rules/                   # Directory for JSON rule files
├── utils/                   # Utility modules
│   └── qrylib/             # Query library files
└── templates/              # Optional: Report templates
----

== Required File: __init__.py

The plugin class MUST implement the BasePlugin interface with COMPLETE, FUNCTIONAL implementations:

[source,python]
----
import importlib.util
from pathlib import Path
import json
from plugins.base import BasePlugin
from .connector import {{ TechnologyNameCamelCase }}Connector

class {{ TechnologyNameCamelCase }}Plugin(BasePlugin):
    """The {{ technology_name }} implementation of the plugin interface."""

    @property
    def technology_name(self):
        return "{{ technology_name_lowercase }}"

    def get_connector(self, settings):
        """Returns an instance of the {{ technology_name }} connector."""
        return {{ TechnologyNameCamelCase }}Connector(settings)

    def get_rules_config(self):
        """
        Dynamically discovers and loads all .json rule files
        from the 'rules' directory.
        
        Returns:
            dict: All rules merged into a single dictionary
        """
        all_rules = {}
        rules_dir = Path(__file__).parent / 'rules'

        if not rules_dir.is_dir():
            print(f"⚠️ Warning: Rules directory not found at {rules_dir}")
            return {}

        for rule_file in rules_dir.glob('*.json'):
            try:
                with open(rule_file, 'r') as f:
                    loaded_rules = json.load(f)
                    all_rules.update(loaded_rules)
            except json.JSONDecodeError as e:
                print(f"⚠️ Warning: Could not parse rule file {rule_file.name}. Error: {e}")
            except IOError as e:
                print(f"⚠️ Warning: Could not read rule file {rule_file.name}. Error: {e}")

        return all_rules

    def get_report_definition(self, report_config_file=None):
        """
        Dynamically loads a report definition from a Python file.
        Falls back to reports/default.py if not specified.
        
        Args:
            report_config_file: Optional path to custom report file
            
        Returns:
            list: REPORT_SECTIONS list from the report module
        """
        if report_config_file:
            config_path = Path(report_config_file)
        else:
            config_path = Path(__file__).parent / "reports" / "default.py"

        if not config_path.is_file():
            raise FileNotFoundError(f"Report configuration file not found: {config_path}")

        # Dynamically import the report module
        spec = importlib.util.spec_from_file_location("report_config_module", config_path)
        report_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(report_module)
        
        return getattr(report_module, 'REPORT_SECTIONS')

    def get_template_path(self) -> Path:
        """Returns the path to this plugin's templates directory."""
        return Path(__file__).parent / "templates"

    # Optional: Override these methods for enhanced functionality
    def get_module_weights(self) -> dict:
        """
        Dynamically discovers check weights by importing each check module.
        Override this if you want custom weight calculation logic.
        """
        weights = {}
        try:
            report_sections = self.get_report_definition()
            for section in report_sections:
                module_name = section.get('module')
                if not module_name:
                    continue
                
                try:
                    # Extract just the module name from full path
                    if 'plugins.{{ technology_name_lowercase }}.checks.' in module_name:
                        short_name = module_name.split('.')[-1]
                        spec = importlib.util.find_spec(f"plugins.{{ technology_name_lowercase }}.checks.{short_name}")
                        if spec:
                            check_module = spec.loader.load_module()
                            if hasattr(check_module, 'get_weight'):
                                weights[short_name] = check_module.get_weight()
                except Exception as e:
                    print(f"⚠️ Could not load weight for '{module_name}': {e}")
        except Exception:
            pass  # Return empty dict if report loading fails
        
        return weights

    def get_db_version_from_findings(self, findings: dict) -> str:
        """
        Extracts database version from findings structure.
        Override this to match your specific findings structure.
        
        Args:
            findings: The structured_findings dictionary
            
        Returns:
            str: Database version or "N/A"
        """
        # TODO: Implement based on your findings structure
        # Example patterns:
        # return findings.get("system_info", {}).get("version", "N/A")
        # return findings.get("{{ technology_name_lowercase }}_overview", {}).get("version", {}).get("data", [{}])[0].get("version", "N/A")
        return "N/A"

    def get_db_name_from_findings(self, findings: dict) -> str:
        """
        Extracts database name from findings structure.
        Override this to match your specific findings structure.
        
        Args:
            findings: The structured_findings dictionary
            
        Returns:
            str: Database name or "N/A"
        """
        # TODO: Implement based on your findings structure
        return "N/A"
----

== Required File: connector.py

The connector MUST provide these methods for framework compatibility:

=== Required Methods

1. `__init__(self, settings)` - Initialize with settings dict
2. `connect(self)` - Establish connection
3. `disconnect(self)` - Close connection gracefully
4. `execute_query(self, query, params=None, return_raw=False)` - Execute queries
5. `get_db_metadata(self)` - **CRITICAL** - Return version and db_name

=== Optional But Recommended

6. `_get_version_info(self)` - Private method to detect version (if applicable)
7. `version_info` property - Expose version information
8. Technology-specific capability detection methods

== Connector Examples by Technology

=== Example 1: SQL Database (PostgreSQL - Primary Reference)

This is the most complete example, suitable for all SQL-based databases:

[source,python]
----
import psycopg2
import psycopg2.extras
import logging

logger = logging.getLogger(__name__)

class {{ TechnologyNameCamelCase }}Connector:
    """Handles all direct communication with {{ technology_name }}."""

    def __init__(self, settings):
        self.settings = settings
        self.conn = None
        self.cursor = None
        self.version_info = {}

    def connect(self):
        """Establishes a connection to the database."""
        try:
            timeout = self.settings.get('statement_timeout', 30000)
            self.conn = psycopg2.connect(
                host=self.settings.get('host', 'localhost'),
                port=self.settings.get('port', 5432),
                dbname=self.settings.get('database', 'postgres'),
                user=self.settings.get('user'),
                password=self.settings.get('password'),
                options=f"-c statement_timeout={timeout}"
            )
            self.conn.autocommit = self.settings.get('autocommit', True)
            self.cursor = self.conn.cursor()
            
            # Fetch version info immediately after connecting
            self.version_info = self._get_version_info()
            
            print(f"✅ Successfully connected to {{ technology_name }}.")
            print(f"   - Version: {self.version_info.get('version_string', 'Unknown')}")
            
        except psycopg2.Error as e:
            logger.error(f"Failed to connect to {{ technology_name }}: {e}")
            raise ConnectionError(f"Could not connect to {{ technology_name }}: {e}")

    def disconnect(self):
        """Closes the database connection."""
        if self.conn:
            try:
                self.conn.close()
                print(f"🔌 Disconnected from {{ technology_name }}.")
            except Exception as e:
                logger.warning(f"Error during disconnect: {e}")
            finally:
                self.conn = None
                self.cursor = None

    def _get_version_info(self):
        """
        Fetches and parses database version information.
        
        Returns:
            dict: Version information with flags
        """
        try:
            self.cursor.execute("SELECT version()")
            version_string = self.cursor.fetchone()[0]
            
            # Parse version string (adapt for your database)
            # PostgreSQL: "PostgreSQL 14.5..."
            # MySQL: "8.0.32"
            # Extract major version number
            import re
            version_match = re.search(r'(\d+)\.(\d+)', version_string)
            if version_match:
                major = int(version_match.group(1))
                minor = int(version_match.group(2))
            else:
                major, minor = 0, 0
            
            return {
                'version_string': version_string,
                'major_version': major,
                'minor_version': minor,
                # Add version flags as needed for your checks
                'is_v10_or_newer': major >= 10,
                'is_v12_or_newer': major >= 12,
                'is_v14_or_newer': major >= 14,
                'is_v15_or_newer': major >= 15,
                'is_v17_or_newer': major >= 17,
            }
        except Exception as e:
            logger.warning(f"Could not fetch version info: {e}")
            return {
                'version_string': 'Unknown',
                'major_version': 0,
                'minor_version': 0,
                'is_v10_or_newer': False,
                'is_v12_or_newer': False,
                'is_v14_or_newer': False,
                'is_v15_or_newer': False,
                'is_v17_or_newer': False,
            }

    def get_db_metadata(self):
        """
        Fetches basic metadata required by the framework.
        
        CRITICAL: This method is called by main.py and MUST return
        a dict with 'version' and 'db_name' keys.
        
        Returns:
            dict: {'version': str, 'db_name': str}
        """
        try:
            # Get database name
            self.cursor.execute("SELECT current_database()")
            db_name = self.cursor.fetchone()[0]
            
            return {
                'version': self.version_info.get('version_string', 'N/A'),
                'db_name': db_name
            }
        except Exception as e:
            logger.warning(f"Could not fetch database metadata: {e}")
            return {
                'version': self.version_info.get('version_string', 'N/A'),
                'db_name': 'N/A'
            }

    def execute_query(self, query, params=None, is_check=False, return_raw=False):
        """
        Executes a query and returns formatted results.
        
        Args:
            query: SQL query string
            params: Optional query parameters (for parameterized queries)
            is_check: If True, returns single value (for boolean checks)
            return_raw: If True, returns (formatted, raw_dict)
        
        Returns:
            str or tuple: Formatted AsciiDoc string, optionally with raw data
        """
        try:
            if not self.cursor or self.cursor.closed:
                self.cursor = self.conn.cursor()

            # Use parameterized queries for safety
            self.cursor.execute(query, params)
            
            # Handle boolean/single-value checks
            if is_check:
                result = self.cursor.fetchone()[0] if self.cursor.rowcount > 0 else ""
                return (str(result), result) if return_raw else str(result)
            
            # Handle statements that don't return rows
            if self.cursor.description is None:
                return ("", []) if return_raw else ""

            columns = [desc[0] for desc in self.cursor.description]
            results = self.cursor.fetchall()
            raw_results = [dict(zip(columns, row)) for row in results]

            # Handle empty results
            if not results:
                formatted = "[NOTE]\n====\nNo results returned.\n====\n"
                return (formatted, []) if return_raw else formatted

            # Format as AsciiDoc table
            table = ['|===', '|' + '|'.join(columns)]
            for row in results:
                # Sanitize pipe characters to prevent table breaks
                sanitized = [str(v).replace('|', '\\|') if v is not None else '' for v in row]
                table.append('|' + '|'.join(sanitized))
            table.append('|===')
            formatted = '\n'.join(table)
            
            return (formatted, raw_results) if return_raw else formatted
            
        except psycopg2.Error as e:
            # Rollback on error to prevent transaction issues
            if self.conn:
                self.conn.rollback()
            
            logger.error(f"Query failed: {e}")
            error_str = f"[ERROR]\n====\nQuery failed: {e}\n====\n"
            error_dict = {"error": str(e), "query": query[:200]}
            
            return (error_str, error_dict) if return_raw else error_str
----

=== Example 2: Key-Value Store (Redis/Valkey)

[source,python]
----
import redis
import logging

logger = logging.getLogger(__name__)

class {{ TechnologyNameCamelCase }}Connector:
    """Handles all direct communication with {{ technology_name }}."""

    def __init__(self, settings):
        self.settings = settings
        self.conn = None
        self.version_info = {}

    def connect(self):
        """Establishes a connection to the database."""
        try:
            self.conn = redis.Redis(
                host=self.settings.get('host', 'localhost'),
                port=self.settings.get('port', 6379),
                password=self.settings.get('password'),
                db=self.settings.get('db', 0),
                decode_responses=True,  # Important: get strings not bytes
                socket_timeout=self.settings.get('timeout', 30)
            )
            
            # Test connection
            self.conn.ping()
            
            # Get version info
            self.version_info = self._get_version_info()
            
            print(f"✅ Successfully connected to {{ technology_name }}.")
            print(f"   - Version: {self.version_info.get('version_string', 'Unknown')}")
            
        except redis.RedisError as e:
            logger.error(f"Failed to connect to {{ technology_name }}: {e}")
            raise ConnectionError(f"Could not connect to {{ technology_name }}: {e}")

    def disconnect(self):
        """Closes the connection."""
        if self.conn:
            try:
                self.conn.close()
                print(f"🔌 Disconnected from {{ technology_name }}.")
            except Exception as e:
                logger.warning(f"Error during disconnect: {e}")
            finally:
                self.conn = None

    def _get_version_info(self):
        """Fetches version information."""
        try:
            info = self.conn.info('server')
            version_string = info.get('redis_version', 'Unknown')
            
            # Parse version (e.g., "7.0.5")
            parts = version_string.split('.')
            major = int(parts[0]) if len(parts) > 0 else 0
            
            return {
                'version_string': version_string,
                'major_version': major,
                'is_v6_or_newer': major >= 6,
                'is_v7_or_newer': major >= 7,
            }
        except Exception as e:
            logger.warning(f"Could not fetch version: {e}")
            return {
                'version_string': 'Unknown',
                'major_version': 0,
                'is_v6_or_newer': False,
                'is_v7_or_newer': False,
            }

    def get_db_metadata(self):
        """
        Fetches database metadata.
        
        Returns:
            dict: {'version': str, 'db_name': str}
        """
        try:
            db_num = self.settings.get('db', 0)
            return {
                'version': self.version_info.get('version_string', 'N/A'),
                'db_name': f"db{db_num}"
            }
        except Exception as e:
            logger.warning(f"Could not fetch metadata: {e}")
            return {'version': 'N/A', 'db_name': 'N/A'}

    def execute_query(self, query, params=None, return_raw=False):
        """
        Executes a Redis command and returns formatted results.
        
        Args:
            query: Redis command string (e.g., "INFO MEMORY", "GET key")
            params: Not used for Redis
            return_raw: If True, returns (formatted, raw_dict)
        
        Returns:
            str or tuple: Formatted results
        """
        try:
            query = query.strip()
            parts = query.split(None, 1)  # Split on first space
            command = parts[0].upper()
            args = parts[1] if len(parts) > 1 else None
            
            raw_results = {}
            
            # Handle INFO commands
            if command == 'INFO':
                section = args.lower() if args else 'default'
                raw_results = self.conn.info(section)
            
            # Handle simple commands
            elif command == 'DBSIZE':
                raw_results = {'dbsize': self.conn.dbsize()}
            
            elif command == 'PING':
                raw_results = {'ping': self.conn.ping()}
            
            # Handle key operations
            elif command in ('GET', 'SET', 'DEL', 'EXISTS', 'TTL'):
                if not args:
                    raise ValueError(f"{command} requires arguments")
                
                if command == 'GET':
                    value = self.conn.get(args)
                    raw_results = {'key': args, 'value': value}
                elif command == 'EXISTS':
                    exists = self.conn.exists(args)
                    raw_results = {'key': args, 'exists': bool(exists)}
                elif command == 'TTL':
                    ttl = self.conn.ttl(args)
                    raw_results = {'key': args, 'ttl': ttl}
                # Add more as needed
            
            else:
                raise NotImplementedError(
                    f"Command '{command}' not yet supported. "
                    "Add support in connector.py execute_query method."
                )
            
            # Format results as AsciiDoc table
            if isinstance(raw_results, dict):
                columns = ['Metric', 'Value']
                table = ['|===', '|' + '|'.join(columns)]
                for key, value in raw_results.items():
                    table.append(f'|{key}|{value}')
                table.append('|===')
                formatted = '\n'.join(table)
            else:
                formatted = str(raw_results)
            
            return (formatted, raw_results) if return_raw else formatted
            
        except redis.RedisError as e:
            logger.error(f"Command failed: {e}")
            error_msg = f"[ERROR]\n====\nRedis error: {str(e)}\n====\n"
            return (error_msg, {'error': str(e)}) if return_raw else error_msg
        except Exception as e:
            logger.error(f"Command execution error: {e}")
            error_msg = f"[ERROR]\n====\n{str(e)}\n====\n"
            return (error_msg, {'error': str(e)}) if return_raw else error_msg
----

=== Example 3: Document Store (MongoDB)

[source,python]
----
import pymongo
import json
from bson import json_util
import logging

logger = logging.getLogger(__name__)

class {{ TechnologyNameCamelCase }}Connector:
    """Handles all direct communication with {{ technology_name }}."""

    def __init__(self, settings):
        self.settings = settings
        self.client = None
        self.db = None
        self.version_info = {}

    def connect(self):
        """Establishes a connection to the database."""
        try:
            connection_string = self.settings.get('connection_string')
            if connection_string:
                self.client = pymongo.MongoClient(connection_string)
            else:
                self.client = pymongo.MongoClient(
                    host=self.settings.get('host', 'localhost'),
                    port=self.settings.get('port', 27017),
                    username=self.settings.get('user'),
                    password=self.settings.get('password'),
                    serverSelectionTimeoutMS=self.settings.get('timeout', 30000)
                )
            
            self.db = self.client[self.settings.get('database', 'admin')]
            
            # Test connection
            self.client.admin.command('ping')
            
            # Get version info
            self.version_info = self._get_version_info()
            
            print(f"✅ Successfully connected to {{ technology_name }}.")
            print(f"   - Version: {self.version_info.get('version_string', 'Unknown')}")
            
        except pymongo.errors.PyMongoError as e:
            logger.error(f"Failed to connect to {{ technology_name }}: {e}")
            raise ConnectionError(f"Could not connect to {{ technology_name }}: {e}")

    def disconnect(self):
        """Closes the connection."""
        if self.client:
            try:
                self.client.close()
                print(f"🔌 Disconnected from {{ technology_name }}.")
            except Exception as e:
                logger.warning(f"Error during disconnect: {e}")
            finally:
                self.client = None
                self.db = None

    def _get_version_info(self):
        """Fetches version information."""
        try:
            build_info = self.client.admin.command('buildInfo')
            version_string = build_info.get('version', 'Unknown')
            
            # Parse version
            parts = version_string.split('.')
            major = int(parts[0]) if len(parts) > 0 else 0
            
            return {
                'version_string': version_string,
                'major_version': major,
                'is_v4_or_newer': major >= 4,
                'is_v5_or_newer': major >= 5,
                'is_v6_or_newer': major >= 6,
            }
        except Exception as e:
            logger.warning(f"Could not fetch version: {e}")
            return {
                'version_string': 'Unknown',
                'major_version': 0,
                'is_v4_or_newer': False,
                'is_v5_or_newer': False,
                'is_v6_or_newer': False,
            }

    def get_db_metadata(self):
        """
        Fetches database metadata.
        
        Returns:
            dict: {'version': str, 'db_name': str}
        """
        try:
            db_name = self.settings.get('database', 'admin')
            return {
                'version': self.version_info.get('version_string', 'N/A'),
                'db_name': db_name
            }
        except Exception as e:
            logger.warning(f"Could not fetch metadata: {e}")
            return {'version': 'N/A', 'db_name': 'N/A'}

    def execute_query(self, query, params=None, return_raw=False):
        """
        Executes a MongoDB query and returns formatted results.
        
        Query format (JSON string):
        {
            "collection": "collection_name",
            "operation": "find" | "aggregate" | "count",
            "filter": {...},     # For find/count
            "pipeline": [...],   # For aggregate
            "limit": 100
        }
        
        Args:
            query: JSON string with query configuration
            params: Not used
            return_raw: If True, returns (formatted, raw_list)
        
        Returns:
            str or tuple: Formatted results
        """
        try:
            # Parse query JSON
            try:
                query_obj = json.loads(query)
            except json.JSONDecodeError as e:
                raise ValueError(f"Invalid JSON query: {e}")
            
            # Validate required fields
            if 'collection' not in query_obj:
                raise ValueError("Query must include 'collection' field")
            
            collection_name = query_obj['collection']
            operation = query_obj.get('operation', 'find')
            limit = query_obj.get('limit', 100)
            
            # Get collection
            collection = self.db[collection_name]
            
            # Execute operation
            if operation == 'find':
                filter_query = query_obj.get('filter', {})
                cursor = collection.find(filter_query).limit(limit)
                raw_results_bson = list(cursor)
            
            elif operation == 'aggregate':
                pipeline = query_obj.get('pipeline', [])
                if not isinstance(pipeline, list):
                    raise ValueError("'pipeline' must be a list")
                cursor = collection.aggregate(pipeline)
                raw_results_bson = list(cursor)
            
            elif operation == 'count':
                filter_query = query_obj.get('filter', {})
                count = collection.count_documents(filter_query)
                raw_results = {'count': count}
                formatted = f"Count: {count}"
                return (formatted, raw_results) if return_raw else formatted
            
            else:
                raise ValueError(f"Unsupported operation: {operation}")
            
            # Convert BSON to JSON-serializable format
            raw_results = json.loads(json_util.dumps(raw_results_bson))
            
            # Format results
            if not raw_results:
                formatted = "[NOTE]\n====\nNo results returned.\n====\n"
                return (formatted, []) if return_raw else formatted
            
            # Build AsciiDoc table
            columns = list(raw_results[0].keys())
            table = ['|===', '|' + '|'.join(columns)]
            for doc in raw_results:
                # Truncate long values
                row_values = [str(doc.get(col, ''))[:50] for col in columns]
                table.append('|' + '|'.join(row_values))
            table.append('|===')
            
            if len(raw_results) == limit:
                table.append(f"\n[NOTE]\n====\nShowing first {limit} results.\n====")
            
            formatted = '\n'.join(table)
            
            return (formatted, raw_results) if return_raw else formatted
            
        except pymongo.errors.PyMongoError as e:
            logger.error(f"MongoDB operation failed: {e}")
            error_msg = f"[ERROR]\n====\nMongoDB error: {str(e)}\n====\n"
            return (error_msg, {'error': str(e)}) if return_raw else error_msg
        except Exception as e:
            logger.error(f"Query execution error: {e}")
            error_msg = f"[ERROR]\n====\n{str(e)}\n====\n"
            return (error_msg, {'error': str(e)}) if return_raw else error_msg
----

=== Example 4: Wide-Column Store (Cassandra)

[source,python]
----
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
from cassandra.query import dict_factory
import logging

logger = logging.getLogger(__name__)

class {{ TechnologyNameCamelCase }}Connector:
    """Handles all direct communication with {{ technology_name }}."""

    def __init__(self, settings):
        self.settings = settings
        self.cluster = None
        self.session = None
        self.version_info = {}

    def connect(self):
        """Establishes a connection to the cluster."""
        try:
            contact_points = self.settings.get('hosts', ['localhost'])
            port = self.settings.get('port', 9042)
            
            auth_provider = None
            if self.settings.get('user') and self.settings.get('password'):
                auth_provider = PlainTextAuthProvider(
                    username=self.settings.get('user'),
                    password=self.settings.get('password')
                )
            
            self.cluster = Cluster(
                contact_points=contact_points,
                port=port,
                auth_provider=auth_provider
            )
            
            self.session = self.cluster.connect()
            self.session.row_factory = dict_factory  # Return dicts
            
            # Set keyspace if specified
            keyspace = self.settings.get('keyspace')
            if keyspace:
                self.session.set_keyspace(keyspace)
            
            # Get version info
            self.version_info = self._get_version_info()
            
            print(f"✅ Successfully connected to {{ technology_name }}.")
            print(f"   - Version: {self.version_info.get('version_string', 'Unknown')}")
            
        except Exception as e:
            logger.error(f"Failed to connect to {{ technology_name }}: {e}")
            raise ConnectionError(f"Could not connect to {{ technology_name }}: {e}")

    def disconnect(self):
        """Closes the connection."""
        if self.cluster:
            try:
                self.cluster.shutdown()
                print(f"🔌 Disconnected from {{ technology_name }}.")
            except Exception as e:
                logger.warning(f"Error during disconnect: {e}")
            finally:
                self.cluster = None
                self.session = None

    def _get_version_info(self):
        """Fetches version information."""
        try:
            rows = self.session.execute("SELECT release_version FROM system.local")
            version_string = rows[0]['release_version'] if rows else 'Unknown'
            
            # Parse version
            parts = version_string.split('.')
            major = int(parts[0]) if len(parts) > 0 else 0
            
            return {
                'version_string': version_string,
                'major_version': major,
                'is_v3_or_newer': major >= 3,
                'is_v4_or_newer': major >= 4,
            }
        except Exception as e:
            logger.warning(f"Could not fetch version: {e}")
            return {
                'version_string': 'Unknown',
                'major_version': 0,
                'is_v3_or_newer': False,
                'is_v4_or_newer': False,
            }

    def get_db_metadata(self):
        """
        Fetches database metadata.
        
        Returns:
            dict: {'version': str, 'db_name': str}
        """
        try:
            keyspace = self.settings.get('keyspace', 'system')
            return {
                'version': self.version_info.get('version_string', 'N/A'),
                'db_name': keyspace
            }
        except Exception as e:
            logger.warning(f"Could not fetch metadata: {e}")
            return {'version': 'N/A', 'db_name': 'N/A'}

    def execute_query(self, query, params=None, return_raw=False):
        """
        Executes a CQL query and returns formatted results.
        
        Args:
            query: CQL query string
            params: Optional query parameters
            return_raw: If True, returns (formatted, raw_list)
        
        Returns:
            str or tuple: Formatted results
        """
        try:
            # Execute query
            if params:
                rows = self.session.execute(query, params)
            else:
                rows = self.session.execute(query)
            
            # Convert to list of dicts
            raw_results = list(rows)
            
            # Handle empty results
            if not raw_results:
                formatted = "[NOTE]\n====\nNo results returned.\n====\n"
                return (formatted, []) if return_raw else formatted
            
            # Build AsciiDoc table
            columns = list(raw_results[0].keys())
            table = ['|===', '|' + '|'.join(columns)]
            for row in raw_results:
                row_values = [str(row.get(col, '')) for col in columns]
                table.append('|' + '|'.join(row_values))
            table.append('|===')
            formatted = '\n'.join(table)
            
            return (formatted, raw_results) if return_raw else formatted
            
        except Exception as e:
            logger.error(f"CQL query failed: {e}")
            error_msg = f"[ERROR]\n====\nQuery failed: {str(e)}\n====\n"
            return (error_msg, {'error': str(e)}) if return_raw else error_msg
----

=== Example 5: Search Engine (OpenSearch/Elasticsearch)

[source,python]
----
from opensearchpy import OpenSearch
import json
import logging

logger = logging.getLogger(__name__)

class {{ TechnologyNameCamelCase }}Connector:
    """Handles all direct communication with {{ technology_name }}."""

    def __init__(self, settings):
        self.settings = settings
        self.client = None
        self.version_info = {}

    def connect(self):
        """Establishes a connection to the cluster."""
        try:
            hosts = self.settings.get('hosts', [{'host': 'localhost', 'port': 9200}])
            
            auth = None
            if self.settings.get('user') and self.settings.get('password'):
                auth = (self.settings.get('user'), self.settings.get('password'))
            
            self.client = OpenSearch(
                hosts=hosts,
                http_auth=auth,
                use_ssl=self.settings.get('use_ssl', False),
                verify_certs=self.settings.get('verify_certs', False),
                timeout=self.settings.get('timeout', 30)
            )
            
            # Test connection
            info = self.client.info()
            
            # Get version info
            self.version_info = self._get_version_info(info)
            
            print(f"✅ Successfully connected to {{ technology_name }}.")
            print(f"   - Version: {self.version_info.get('version_string', 'Unknown')}")
            
        except Exception as e:
            logger.error(f"Failed to connect to {{ technology_name }}: {e}")
            raise ConnectionError(f"Could not connect to {{ technology_name }}: {e}")

    def disconnect(self):
        """Closes the connection."""
        if self.client:
            try:
                # OpenSearch client doesn't need explicit disconnect
                print(f"🔌 Disconnected from {{ technology_name }}.")
            except Exception as e:
                logger.warning(f"Error during disconnect: {e}")
            finally:
                self.client = None

    def _get_version_info(self, info):
        """Parses version from cluster info."""
        try:
            version_string = info.get('version', {}).get('number', 'Unknown')
            
            # Parse version
            parts = version_string.split('.')
            major = int(parts[0]) if len(parts) > 0 else 0
            
            return {
                'version_string': version_string,
                'major_version': major,
                'is_v1_or_newer': major >= 1,
                'is_v2_or_newer': major >= 2,
            }
        except Exception as e:
            logger.warning(f"Could not parse version: {e}")
            return {
                'version_string': 'Unknown',
                'major_version': 0,
                'is_v1_or_newer': False,
                'is_v2_or_newer': False,
            }

    def get_db_metadata(self):
        """
        Fetches cluster metadata.
        
        Returns:
            dict: {'version': str, 'db_name': str}
        """
        try:
            cluster_name = self.client.info().get('cluster_name', 'Unknown')
            return {
                'version': self.version_info.get('version_string', 'N/A'),
                'db_name': cluster_name
            }
        except Exception as e:
            logger.warning(f"Could not fetch metadata: {e}")
            return {'version': 'N/A', 'db_name': 'N/A'}

    def execute_query(self, query, params=None, return_raw=False):
        """
        Executes an OpenSearch API call.
        
        Query format (JSON string):
        {
            "endpoint": "/_cluster/health" or "/_search",
            "method": "GET" | "POST",
            "body": {...},  # Optional request body
            "params": {...}  # Optional query parameters
        }
        
        Args:
            query: JSON string with API call configuration
            params: Not used
            return_raw: If True, returns (formatted, raw_dict)
        
        Returns:
            str or tuple: Formatted results
        """
        try:
            # Parse query
            query_obj = json.loads(query)
            endpoint = query_obj.get('endpoint', '/_cluster/health')
            method = query_obj.get('method', 'GET').upper()
            body = query_obj.get('body')
            query_params = query_obj.get('params', {})
            
            # Execute API call
            if method == 'GET':
                response = self.client.transport.perform_request(
                    'GET', endpoint, params=query_params
                )
            elif method == 'POST':
                response = self.client.transport.perform_request(
                    'POST', endpoint, params=query_params, body=body
                )
            else:
                raise ValueError(f"Unsupported method: {method}")
            
            raw_results = response
            
            # Format based on endpoint type
            if '_cluster/health' in endpoint:
                formatted = f"Cluster Status: {raw_results.get('status', 'unknown')}\n"
                formatted += f"Nodes: {raw_results.get('number_of_nodes', 0)}\n"
                formatted += f"Active Shards: {raw_results.get('active_shards', 0)}"
            elif '_search' in endpoint:
                hits = raw_results.get('hits', {}).get('total', {})
                count = hits.get('value', 0) if isinstance(hits, dict) else hits
                formatted = f"Search returned {count} results"
            else:
                # Generic formatting
                formatted = json.dumps(raw_results, indent=2)
            
            return (formatted, raw_results) if return_raw else formatted
            
        except Exception as e:
            logger.error(f"API call failed: {e}")
            error_msg = f"[ERROR]\n====\n{str(e)}\n====\n"
            return (error_msg, {'error': str(e)}) if return_raw else error_msg
----

=== Example 6: Streaming Platform (Kafka)

[source,python]
----
from kafka.admin import KafkaAdminClient
from kafka import KafkaConsumer
import json
import logging

logger = logging.getLogger(__name__)

class {{ TechnologyNameCamelCase }}Connector:
    """Handles all direct communication with {{ technology_name }}."""

    def __init__(self, settings):
        self.settings = settings
        self.admin_client = None
        self.version_info = {}

    def connect(self):
        """Establishes a connection to the Kafka cluster."""
        try:
            bootstrap_servers = self.settings.get('bootstrap_servers', ['localhost:9092'])
            
            self.admin_client = KafkaAdminClient(
                bootstrap_servers=bootstrap_servers,
                client_id='healthcheck_client'
            )
            
            # Get version/broker info
            self.version_info = self._get_version_info()
            
            print(f"✅ Successfully connected to {{ technology_name }}.")
            print(f"   - Brokers: {len(bootstrap_servers)}")
            
        except Exception as e:
            logger.error(f"Failed to connect to {{ technology_name }}: {e}")
            raise ConnectionError(f"Could not connect to {{ technology_name }}: {e}")

    def disconnect(self):
        """Closes the connection."""
        if self.admin_client:
            try:
                self.admin_client.close()
                print(f"🔌 Disconnected from {{ technology_name }}.")
            except Exception as e:
                logger.warning(f"Error during disconnect: {e}")
            finally:
                self.admin_client = None

    def _get_version_info(self):
        """Fetches broker version information."""
        try:
            # Kafka doesn't have a simple version query
            # Would need to parse from broker metadata
            return {
                'version_string': 'Unknown',
                'major_version': 0,
            }
        except Exception as e:
            logger.warning(f"Could not fetch version: {e}")
            return {
                'version_string': 'Unknown',
                'major_version': 0,
            }

    def get_db_metadata(self):
        """
        Fetches cluster metadata.
        
        Returns:
            dict: {'version': str, 'db_name': str}
        """
        try:
            cluster_id = self.admin_client.describe_cluster().get('cluster_id', 'Unknown')
            return {
                'version': self.version_info.get('version_string', 'N/A'),
                'db_name': cluster_id
            }
        except Exception as e:
            logger.warning(f"Could not fetch metadata: {e}")
            return {'version': 'N/A', 'db_name': 'N/A'}

    def execute_query(self, query, params=None, return_raw=False):
        """
        Executes a Kafka admin operation or metric query.
        
        Query format (JSON string):
        {
            "operation": "list_topics" | "consumer_lag" | "broker_metrics",
            "group_id": "consumer_group"  # For consumer_lag
        }
        
        Args:
            query: JSON string with operation configuration
            params: Not used
            return_raw: If True, returns (formatted, raw_dict)
        
        Returns:
            str or tuple: Formatted results
        """
        try:
            query_obj = json.loads(query)
            operation = query_obj.get('operation', 'list_topics')
            
            if operation == 'list_topics':
                topics = self.admin_client.list_topics()
                raw_results = {'topics': topics}
                formatted = f"Topics: {len(topics)}\n" + '\n'.join(topics)
            
            elif operation == 'consumer_lag':
                # Would need to implement consumer lag calculation
                raw_results = {'lag': 'Not implemented'}
                formatted = "Consumer lag check not yet implemented"
            
            else:
                raise ValueError(f"Unsupported operation: {operation}")
            
            return (formatted, raw_results) if return_raw else formatted
            
        except Exception as e:
            logger.error(f"Operation failed: {e}")
            error_msg = f"[ERROR]\n====\n{str(e)}\n====\n"
            return (error_msg, {'error': str(e)}) if return_raw else error_msg
----

== Output Format (CRITICAL)

Your response MUST be a JSON object with "operations" and "post_message":

[source,json]
----
{
  "operations": [
    {
      "action": "create_directory",
      "path": "plugins/{{ technology_name_lowercase }}"
    },
    {
      "action": "create_file",
      "path": "plugins/{{ technology_name_lowercase }}/__init__.py",
      "content": "... complete __init__.py content ..."
    },
    {
      "action": "create_file",
      "path": "plugins/{{ technology_name_lowercase }}/connector.py",
      "content": "... complete connector.py content ..."
    },
    {
      "action": "create_directory",
      "path": "plugins/{{ technology_name_lowercase }}/checks"
    },
    {
      "action": "create_directory",
      "path": "plugins/{{ technology_name_lowercase }}/reports"
    },
    {
      "action": "create_directory",
      "path": "plugins/{{ technology_name_lowercase }}/rules"
    },
    {
      "action": "create_directory",
      "path": "plugins/{{ technology_name_lowercase }}/utils"
    },
    {
      "action": "create_directory",
      "path": "plugins/{{ technology_name_lowercase }}/utils/qrylib"
    },
    {
      "action": "create_directory",
      "path": "plugins/{{ technology_name_lowercase }}/templates"
    }
  ],
  "post_message": "✅ Successfully scaffolded {{ technology_name }} plugin at plugins/{{ technology_name_lowercase }}/\n\nNext steps:\n1. Add checks: python3 aidev.py 'add a {{ technology_name_lowercase }} check for [your check]'\n2. Create report definition in plugins/{{ technology_name_lowercase }}/reports/default.py\n3. Test connection: Review connector.py and adjust for your environment"
}
----

== Pre-Submission Validation

Before outputting JSON, verify:

✅ Input validation passed
✅ Technology analyzed and appropriate connector selected
✅ __init__.py has COMPLETE implementations (not placeholders)
✅ Connector has get_db_metadata() method (CRITICAL)
✅ Connector has _get_version_info() if applicable
✅ Connector has error handling in connect() and execute_query()
✅ All required directories in operations list
✅ File paths start with `plugins/{{ technology_name_lowercase }}/`
✅ No path traversal characters (.., /, ~)

== Your Task

Generate a complete plugin scaffold for:

*Technology Name:* {{ technology_name }}
*Lowercase Name:* {{ technology_name_lowercase }}
*CamelCase Name:* {{ TechnologyNameCamelCase }}

Analyze the technology name, select the appropriate connector pattern, and generate all required files with functional implementations.

Output ONLY the JSON plan. No explanations, no markdown, no additional text.
